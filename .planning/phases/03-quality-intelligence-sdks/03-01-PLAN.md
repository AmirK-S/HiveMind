---
phase: 03-quality-intelligence-sdks
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - alembic/versions/006_quality_temporal.py
  - hivemind/db/models.py
  - hivemind/quality/__init__.py
  - hivemind/quality/scorer.py
  - hivemind/quality/signals.py
  - hivemind/config.py
autonomous: true
requirements:
  - QI-01
  - QI-02
  - KM-05

must_haves:
  truths:
    - "KnowledgeItem has a quality_score column with default 0.5"
    - "KnowledgeItem has four temporal columns: valid_at, invalid_at, expired_at (plus existing contributed_at as system-time created_at)"
    - "A quality_signals table exists to record per-item behavioral signals"
    - "compute_quality_score() returns a float 0-1 from weighted behavioral signals"
    - "record_signal() inserts a row into quality_signals with outcome and item_id"
  artifacts:
    - path: "alembic/versions/006_quality_temporal.py"
      provides: "Alembic migration adding quality + temporal columns and quality_signals table"
      contains: "quality_score"
    - path: "hivemind/quality/scorer.py"
      provides: "Quality score computation from behavioral signals"
      exports: ["compute_quality_score"]
    - path: "hivemind/quality/signals.py"
      provides: "Signal recording and retrieval helpers"
      exports: ["record_signal", "get_signals_for_item"]
    - path: "hivemind/db/models.py"
      provides: "Updated KnowledgeItem + new QualitySignal model"
      contains: "quality_score"
  key_links:
    - from: "hivemind/quality/scorer.py"
      to: "hivemind/db/models.py"
      via: "imports QualitySignal and KnowledgeItem"
      pattern: "from hivemind\\.db\\.models import"
    - from: "hivemind/quality/signals.py"
      to: "hivemind/db/models.py"
      via: "inserts into quality_signals table"
      pattern: "QualitySignal"
---

<objective>
Add quality scoring infrastructure and bi-temporal columns to the knowledge store.

Purpose: This plan creates the data foundation for all Quality Intelligence features. Every subsequent plan in Phase 3 depends on the quality_score column, temporal columns, and quality_signals table created here. Without this schema foundation, quality ranking, temporal queries, outcome reporting, and distillation cannot function.

Output: Alembic migration 006 with new columns/table, QualitySignal ORM model, quality scorer module, signal recording helpers, and updated config settings.
</objective>

<execution_context>
@/Users/amirkellousidhoum/.claude/get-shit-done/workflows/execute-plan.md
@/Users/amirkellousidhoum/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-quality-intelligence-sdks/03-RESEARCH.md

# Existing models — extend KnowledgeItem, add QualitySignal
@hivemind/db/models.py
@hivemind/config.py
@alembic/versions/005_webhook_endpoints.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Schema migration and model updates for quality + temporal columns</name>
  <files>
    alembic/versions/006_quality_temporal.py
    hivemind/db/models.py
  </files>
  <action>
    1. Create Alembic migration `006_quality_temporal.py` (revision chain: down_revision = 005's revision ID — read 005 to get the exact revision hash). The migration adds:
       - On `knowledge_items` table:
         - `quality_score` Float, nullable=False, server_default="0.5" (QI-01: neutral prior for new items)
         - `retrieval_count` Integer, nullable=False, server_default="0" (QI-02: denormalized for dashboard)
         - `helpful_count` Integer, nullable=False, server_default="0" (QI-02: denormalized for dashboard)
         - `not_helpful_count` Integer, nullable=False, server_default="0" (QI-02: denormalized for dashboard)
         - `valid_at` DateTime(timezone=True), nullable=True (KM-05: world-time start — NULL means "valid since approval")
         - `invalid_at` DateTime(timezone=True), nullable=True (KM-05: world-time end — NULL means "still valid")
         - `expired_at` DateTime(timezone=True), nullable=True (KM-05: system-time end — NULL means "current version")
         Note: system-time start is already `contributed_at` (existing column). Do NOT add a duplicate `created_at`.
       - New table `quality_signals`:
         - `id` UUID primary key, default uuid4
         - `knowledge_item_id` UUID, nullable=False, foreign key to knowledge_items.id
         - `signal_type` String(50), nullable=False (e.g. "retrieval", "outcome_solved", "outcome_not_helpful", "contradiction")
         - `agent_id` String(255), nullable=True (agent that generated the signal)
         - `run_id` String(255), nullable=True (for deduplication of outcome reports)
         - `metadata` JSONB, nullable=True (extensible signal-specific data)
         - `created_at` DateTime(timezone=True), nullable=False, default=utcnow
         - Index on `knowledge_item_id` for aggregation queries
         - Index on `(knowledge_item_id, signal_type)` for filtered aggregation
       - Backfill existing `knowledge_items` rows: set `quality_score = confidence * 0.5` (per research Open Question 5 — items with high agent confidence get a slight head start). Use `op.execute(UPDATE knowledge_items SET quality_score = LEAST(1.0, confidence * 0.5))`.
       - Add partial index: `ix_knowledge_items_quality_score` on `quality_score` WHERE `deleted_at IS NULL` — speeds up quality-ranked queries.

    2. Update `hivemind/db/models.py`:
       - Add to KnowledgeItem class: `quality_score`, `retrieval_count`, `helpful_count`, `not_helpful_count`, `valid_at`, `invalid_at`, `expired_at` columns matching the migration schema.
       - Add new `QualitySignal` ORM model class with all columns from the migration.
       - Import `ForeignKey` from sqlalchemy if not already imported.

    AVOID: Do NOT use TSTZRANGE columns — research confirmed SQLAlchemy friction (multiple GitHub issues with DateTimeTZRange DataError). Use four explicit nullable DateTime(timezone=True) columns instead.
    AVOID: Do NOT make `valid_at` NOT NULL — existing items have no world-time data; NULL is semantically correct ("valid since approval time").
  </action>
  <verify>
    Run `cd /Users/amirkellousidhoum/Desktop/Code/HiveMind && python -c "from hivemind.db.models import KnowledgeItem, QualitySignal; print('quality_score' in KnowledgeItem.__table__.columns); print('QualitySignal' in dir())"` — both should print True.
    Run `alembic check` or verify migration file exists and has correct down_revision.
  </verify>
  <done>
    KnowledgeItem ORM model has quality_score (default 0.5), retrieval_count, helpful_count, not_helpful_count, valid_at, invalid_at, expired_at columns. QualitySignal model exists with knowledge_item_id FK, signal_type, agent_id, run_id, metadata, created_at. Alembic migration 006 chains from 005.
  </done>
</task>

<task type="auto">
  <name>Task 2: Quality scorer module and signal recording helpers</name>
  <files>
    hivemind/quality/__init__.py
    hivemind/quality/scorer.py
    hivemind/quality/signals.py
    hivemind/config.py
  </files>
  <action>
    1. Create `hivemind/quality/__init__.py` — empty init file.

    2. Create `hivemind/quality/scorer.py` with `compute_quality_score()` function:
       - Parameters: retrieval_count (int), helpful_count (int), not_helpful_count (int), contradiction_rate (float 0-1), days_since_last_access (float), is_version_current (bool), staleness_half_life_days (float = 90.0)
       - Formula (from research Pattern 3):
         ```
         usefulness = helpful / max(helpful + not_helpful, 1)
         popularity = tanh(retrieval_count / 50)  # saturates at ~200 retrievals
         freshness = exp(-ln(2) * days_since_last_access / half_life)
         version_bonus = 0.1 if is_version_current else 0.0
         raw = 0.40 * usefulness + 0.25 * popularity + 0.20 * freshness
               - 0.15 * contradiction_rate + version_bonus
         return clamp(raw, 0.0, 1.0)
         ```
       - Use `math.tanh`, `math.exp`, `math.log` — no external deps.
       - Add docstring documenting the weight breakdown and that weights are tunable via deployment_config.

    3. Create `hivemind/quality/signals.py` with:
       - `async def record_signal(knowledge_item_id: str, signal_type: str, agent_id: str | None = None, run_id: str | None = None, metadata: dict | None = None) -> str`:
         Inserts a QualitySignal row. Returns the signal ID as string.
         Uses `async with get_session() as session` pattern (same as all other async DB code).
       - `async def get_signals_for_item(knowledge_item_id: str) -> list[dict]`:
         Returns all signals for an item as a list of dicts (id, signal_type, agent_id, created_at).
       - `async def increment_retrieval_count(knowledge_item_id: str) -> None`:
         Atomically increments `retrieval_count` on the KnowledgeItem row.
         Uses `UPDATE knowledge_items SET retrieval_count = retrieval_count + 1 WHERE id = :id`.

    4. Update `hivemind/config.py` — add these settings fields to the Settings class:
       - `quality_staleness_half_life_days: float = 90.0` — half-life for freshness decay
       - `quality_weights_usefulness: float = 0.40`
       - `quality_weights_popularity: float = 0.25`
       - `quality_weights_freshness: float = 0.20`
       - `quality_weights_contradiction: float = 0.15`
       - `distillation_volume_threshold: int = 50` — minimum pending items before distillation runs
       - `distillation_conflict_threshold: int = 5` — minimum unresolved conflicts before distillation runs
       - `minhash_threshold: float = 0.95` — Jaccard similarity threshold for LSH dedup (KM-03)
       - `minhash_num_perm: int = 128` — number of permutations for MinHash
       - `llm_provider: str = "anthropic"` — LLM provider for conflict resolution and dedup stage 3
       - `llm_model: str = "claude-3-haiku-20240307"` — model for conflict resolution

    AVOID: Do NOT read weights from deployment_config table at compute time — pass them as parameters or read from Settings at call time. The deployment_config table pattern is for runtime-mutable settings; quality weights are configuration-time settings via environment variables.
  </action>
  <verify>
    Run `cd /Users/amirkellousidhoum/Desktop/Code/HiveMind && python -c "
from hivemind.quality.scorer import compute_quality_score
score = compute_quality_score(retrieval_count=100, helpful_count=8, not_helpful_count=2, contradiction_rate=0.1, days_since_last_access=30, is_version_current=True)
print(f'Score: {score:.4f}')
assert 0.0 <= score <= 1.0, 'Score out of range'
print('OK')
"` — should print a score between 0 and 1.
  </verify>
  <done>
    compute_quality_score() returns a float 0-1 from weighted behavioral signals with tunable weights from config. record_signal() inserts quality signals. increment_retrieval_count() atomically updates the denormalized counter. Settings includes all Phase 3 configuration fields.
  </done>
</task>

</tasks>

<verification>
1. `python -c "from hivemind.db.models import KnowledgeItem, QualitySignal"` succeeds
2. `python -c "from hivemind.quality.scorer import compute_quality_score"` succeeds
3. `python -c "from hivemind.quality.signals import record_signal, increment_retrieval_count"` succeeds
4. Migration file 006 exists and chains from 005
5. KnowledgeItem.quality_score has server_default 0.5
6. QualitySignal has FK to knowledge_items
</verification>

<success_criteria>
- Quality score formula produces values 0-1 with correct signal weighting
- Temporal columns (valid_at, invalid_at, expired_at) present on KnowledgeItem as nullable DateTime(timezone=True)
- quality_signals table has item FK, signal_type, agent_id, run_id, metadata
- All new config settings have sensible defaults
- Migration backfills existing items with quality_score = confidence * 0.5
</success_criteria>

<output>
After completion, create `.planning/phases/03-quality-intelligence-sdks/03-01-SUMMARY.md`
</output>
