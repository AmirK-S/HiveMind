---
phase: 02-trust-security-hardening
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - hivemind/pipeline/injection.py
  - hivemind/pipeline/integrity.py
  - hivemind/pipeline/pii.py
autonomous: true
requirements: [TRUST-05, TRUST-06, SEC-01, SEC-02]

must_haves:
  truths:
    - "InjectionScanner.get_instance().is_injection(text) returns (bool, float) for any input text"
    - "PIIPipeline.strip() extracts code blocks before PII analysis and reinjects them intact after"
    - "PIIPipeline.strip() runs two-pass validation: re-analyzes anonymized text and verbatim-checks original PII values"
    - "verify_content_hash() returns False when content has been tampered with"
  artifacts:
    - path: "hivemind/pipeline/injection.py"
      provides: "InjectionScanner singleton with DeBERTa-v3 prompt injection classifier"
      contains: "InjectionScanner"
    - path: "hivemind/pipeline/integrity.py"
      provides: "Content hash computation and verification helpers"
      exports: ["compute_content_hash", "verify_content_hash"]
    - path: "hivemind/pipeline/pii.py"
      provides: "Two-pass PII validation with markdown-aware code block preservation"
      contains: "_extract_code_blocks"
  key_links:
    - from: "hivemind/pipeline/injection.py"
      to: "transformers pipeline"
      via: "lazy import in __init__"
      pattern: "pipeline.*text-classification.*deberta"
    - from: "hivemind/pipeline/pii.py"
      to: "_extract_code_blocks / _reinject_code_blocks"
      via: "called in strip() method"
      pattern: "_extract_code_blocks|_reinject_code_blocks"
---

<objective>
Harden the content processing pipeline with prompt injection scanning, two-pass PII validation, markdown-aware code block preservation, and content integrity verification.

Purpose: Before wiring into MCP tools (Plan 05), create the standalone modules and extend the PII pipeline so all security checks are unit-testable in isolation.
Output: Three pipeline modules — injection.py (new), integrity.py (new), pii.py (extended)
</objective>

<execution_context>
@/Users/amirkellousidhoum/.claude/get-shit-done/workflows/execute-plan.md
@/Users/amirkellousidhoum/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-trust-security-hardening/02-RESEARCH.md
@hivemind/pipeline/pii.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create prompt injection scanner and content integrity modules</name>
  <files>hivemind/pipeline/injection.py, hivemind/pipeline/integrity.py</files>
  <action>
Create `hivemind/pipeline/injection.py` with:
- `InjectionScanner` class following the singleton pattern from PIIPipeline (class-level `_instance`, `get_instance()` classmethod)
- `_MODEL_ID = "ProtectAI/deberta-v3-base-prompt-injection-v2"`
- `_THRESHOLD = 0.5` (configurable via constructor param)
- `_MAX_INPUT_CHARS = 2000` — truncate input to prevent OOM on very long text
- Lazy imports: `from transformers import AutoModelForSequenceClassification, AutoTokenizer, pipeline` and `import torch` inside `__init__` only (same pattern as PIIPipeline)
- `__init__` creates a `text-classification` pipeline with `truncation=True, max_length=512`, device auto-detected via `torch.device("cuda" if torch.cuda.is_available() else "cpu")`
- `is_injection(self, text: str, threshold: float | None = None) -> tuple[bool, float]` method:
  - Takes text[:_MAX_INPUT_CHARS]
  - Runs through pipeline
  - Returns `(label == "LABEL_1" and score >= threshold, score)` where threshold defaults to `_THRESHOLD`
  - LABEL_0 = benign, LABEL_1 = injection (per Hugging Face model card)

Create `hivemind/pipeline/integrity.py` with:
- `compute_content_hash(content: str) -> str` — returns `hashlib.sha256(content.encode()).hexdigest()`
- `verify_content_hash(content: str, stored_hash: str) -> bool` — returns `compute_content_hash(content) == stored_hash`
- Import only `hashlib` from stdlib — no external dependencies

Both files: include module docstrings explaining purpose and referencing requirement IDs.
  </action>
  <verify>
Run `python -c "from hivemind.pipeline.injection import InjectionScanner; print('InjectionScanner importable')"` — should print without error.
Run `python -c "from hivemind.pipeline.integrity import compute_content_hash, verify_content_hash; h = compute_content_hash('test'); assert verify_content_hash('test', h); assert not verify_content_hash('tampered', h); print('integrity OK')"` — should print "integrity OK".
  </verify>
  <done>InjectionScanner class is importable with get_instance() method. compute_content_hash and verify_content_hash work correctly for matching and mismatching content.</done>
</task>

<task type="auto">
  <name>Task 2: Extend PII pipeline with two-pass validation and markdown-aware code block preservation</name>
  <files>hivemind/pipeline/pii.py</files>
  <action>
Extend `hivemind/pipeline/pii.py` with the following changes:

**Add code block extraction functions (TRUST-06) at module level, ABOVE the PIIPipeline class:**

```python
_FENCED_CODE_RE = re.compile(r'(```[\s\S]*?```|~~~[\s\S]*?~~~)', re.MULTILINE)
_INLINE_CODE_RE = re.compile(r'(`[^`\n]+`)')
```

Add `_extract_code_blocks(text: str) -> tuple[str, dict[str, str]]`:
- Replace fenced code blocks (```) and tilde blocks (~~~) with UUID placeholders `__CODE_BLOCK_{uuid4.hex}__`
- Then replace inline code blocks (backticks) with `__INLINE_{uuid4.hex}__`
- Order matters: fenced first (so triple backticks are already placeholder'd before inline regex runs — avoids Pitfall 5 from research)
- Return (modified_text, placeholder_map)

Add `_reinject_code_blocks(text: str, placeholder_map: dict[str, str]) -> str`:
- Simple string replacement: for each key in placeholder_map, replace key with original value in text

**Modify `PIIPipeline.strip()` method to implement TRUST-05 + TRUST-06:**

Replace the existing strip() method body with:

1. `narrative, code_map = _extract_code_blocks(text)` — TRUST-06: protect code blocks
2. `results = self._analyzer.analyze(text=narrative, language="en")` — analyze narrative only
3. `original_pii_values = [narrative[r.start:r.end] for r in results]` — capture original PII values for verbatim check
4. `anonymized = self._anonymizer.anonymize(text=narrative, analyzer_results=results, operators=self._operators)` — strip PII
5. `cleaned_narrative = anonymized.text`
6. TRUST-05 Pass 2a: `residual_results = self._analyzer.analyze(text=cleaned_narrative, language="en")` — re-run analyzer on anonymized text
7. If `residual_results` is non-empty, re-strip: `cleaned_narrative = self._anonymizer.anonymize(text=cleaned_narrative, analyzer_results=residual_results, operators=self._operators).text`
8. TRUST-05 Pass 2b: verbatim check — iterate `original_pii_values`, for any value with `len(pii_value) >= 4` (Pitfall 4 from research: short values cause false positives), if it appears in `cleaned_narrative`, replace with `[REDACTED]`
9. `cleaned = _reinject_code_blocks(cleaned_narrative, code_map)` — TRUST-06: restore code blocks
10. Existing 50% rejection check on `cleaned` (unchanged logic)
11. Return `(cleaned, should_reject)`

Add `import uuid` to the imports section (needed for UUID placeholders).

Do NOT change: the `_build_api_key_patterns()`, `_build_operator_config()`, `__init__()`, or `strip_pii()` functions. Only `strip()` method body and new module-level functions/regexes.
  </action>
  <verify>
Run `python -c "
from hivemind.pipeline.pii import PIIPipeline, _extract_code_blocks, _reinject_code_blocks

# Test code block preservation
text = 'Call john@example.com for help.\n\`\`\`python\nemail = \"test@test.com\"\n\`\`\`\nThanks!'
narrative, code_map = _extract_code_blocks(text)
assert 'test@test.com' not in narrative, 'Code block should be extracted'
assert len(code_map) == 1, f'Expected 1 code block, got {len(code_map)}'
restored = _reinject_code_blocks(narrative, code_map)
assert 'test@test.com' in restored, 'Code block should be restored'
print('Code block extraction OK')
"` — should print "Code block extraction OK".
  </verify>
  <done>PIIPipeline.strip() extracts fenced and inline code blocks before PII analysis, runs two-pass validation (re-analyze + verbatim check), and reinjects code blocks intact. Code inside backticks is never touched by the PII scanner.</done>
</task>

</tasks>

<verification>
1. `python -c "from hivemind.pipeline.injection import InjectionScanner"` — imports without error
2. `python -c "from hivemind.pipeline.integrity import compute_content_hash, verify_content_hash"` — imports without error
3. `python -c "from hivemind.pipeline.pii import PIIPipeline, _extract_code_blocks"` — imports without error
4. Content hash verification: `compute_content_hash("x") != compute_content_hash("y")` and `verify_content_hash("x", compute_content_hash("x"))` returns True
5. Code block extraction preserves code content and PII stripping processes only narrative text
</verification>

<success_criteria>
- InjectionScanner singleton loads DeBERTa model lazily and classifies text as injection/benign
- PIIPipeline.strip() is markdown-aware (TRUST-06) and runs two-pass validation (TRUST-05)
- Content integrity helpers compute and verify SHA-256 hashes (SEC-02)
- All three modules are importable and testable in isolation before wiring into MCP tools
</success_criteria>

<output>
After completion, create `.planning/phases/02-trust-security-hardening/02-01-SUMMARY.md`
</output>
