---
phase: 02-trust-security-hardening
plan: 05
type: execute
wave: 2
depends_on: [02-01, 02-02]
files_modified:
  - hivemind/server/tools/add_knowledge.py
  - hivemind/server/tools/search_knowledge.py
autonomous: true
requirements: [TRUST-04, ACL-05, SEC-01, SEC-02]

must_haves:
  truths:
    - "add_knowledge rejects content classified as prompt injection before PII stripping"
    - "add_knowledge checks auto-approve rules and skips pending queue for matching categories"
    - "search_knowledge fetch-by-id verifies content hash and returns tamper warning if mismatch"
    - "search_knowledge deduplicates results by content_hash, preferring private over public copies"
  artifacts:
    - path: "hivemind/server/tools/add_knowledge.py"
      provides: "Injection scanning + auto-approve integration in add_knowledge flow"
      contains: "InjectionScanner"
    - path: "hivemind/server/tools/search_knowledge.py"
      provides: "Content hash verification in fetch + cross-namespace dedup in search"
      contains: "verify_content_hash"
  key_links:
    - from: "hivemind/server/tools/add_knowledge.py"
      to: "hivemind/pipeline/injection.py"
      via: "InjectionScanner.get_instance().is_injection()"
      pattern: "InjectionScanner.get_instance\\(\\).is_injection"
    - from: "hivemind/server/tools/add_knowledge.py"
      to: "hivemind/db/models.py"
      via: "AutoApproveRule query for skip-queue logic"
      pattern: "AutoApproveRule"
    - from: "hivemind/server/tools/search_knowledge.py"
      to: "hivemind/pipeline/integrity.py"
      via: "verify_content_hash() in _fetch_by_id"
      pattern: "verify_content_hash"
---

<objective>
Wire the pipeline hardening (injection scanner, content integrity, auto-approve) into the existing MCP tools. Add cross-namespace deduplication to search results.

Purpose: The standalone modules from Plan 01 and models from Plan 02 are now integrated into the live request flow — agents get injection protection, hash verification, and auto-approve behavior.
Output: Updated add_knowledge.py and search_knowledge.py with security checks wired in.
</objective>

<execution_context>
@/Users/amirkellousidhoum/.claude/get-shit-done/workflows/execute-plan.md
@/Users/amirkellousidhoum/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-trust-security-hardening/02-RESEARCH.md
@.planning/phases/02-trust-security-hardening/02-01-SUMMARY.md
@.planning/phases/02-trust-security-hardening/02-02-SUMMARY.md
@hivemind/server/tools/add_knowledge.py
@hivemind/server/tools/search_knowledge.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Integrate injection scanning and auto-approve into add_knowledge</name>
  <files>hivemind/server/tools/add_knowledge.py</files>
  <action>
Modify `hivemind/server/tools/add_knowledge.py` to add two new steps in the contribution flow:

**Step 1.5 (after auth, before PII strip) — Prompt injection scanning (SEC-01):**

Add import at top: `from hivemind.pipeline.injection import InjectionScanner`

After the auth extraction (Step 1) and before PII stripping (Step 2), add:
```python
# Step 1.5: Scan for prompt injection BEFORE PII stripping (SEC-01)
# Injection patterns may be hidden in text that gets partially redacted —
# scan raw content before any modification.
is_injection, injection_score = InjectionScanner.get_instance().is_injection(content)
if is_injection:
    return CallToolResult(
        content=[TextContent(
            type="text",
            text=(
                f"Rejected: content contains potential prompt injection "
                f"(confidence: {injection_score:.0%}). "
                f"Malicious instructions are not allowed in the commons."
            ),
        )],
        isError=True,
    )
```

**Step 5.5 (after content hash, before insert) — Auto-approve check (TRUST-04):**

Add imports at top: `from hivemind.db.models import AutoApproveRule, KnowledgeItem` (KnowledgeItem is needed for direct insert on auto-approve) and `from sqlalchemy import select`.

After content hash computation (Step 4) and before the DB insert (Step 5), refactor the DB block:

```python
# Step 5: Insert — either directly (auto-approve) or into pending queue
async with get_session() as session:
    # Step 5a: Check auto-approve rules (TRUST-04)
    auto_approve_result = await session.execute(
        select(AutoApproveRule).where(
            AutoApproveRule.org_id == auth.org_id,
            AutoApproveRule.category == category_enum,
            AutoApproveRule.is_auto_approve == True,  # noqa: E712
        )
    )
    auto_approve_rule = auto_approve_result.scalar_one_or_none()

    if auto_approve_rule:
        # Auto-approved: skip pending queue, insert directly with embedding
        embedding = get_embedder().embed(cleaned_content)
        item = KnowledgeItem(
            org_id=auth.org_id,
            source_agent_id=auth.agent_id,
            run_id=run_id,
            content=cleaned_content,
            content_hash=content_hash,
            category=category_enum,
            confidence=confidence,
            framework=framework,
            language=language,
            version=version,
            tags={"tags": tags} if tags else None,
            is_public=False,  # auto-approved items start private
            embedding=embedding,
            contributed_at=datetime.datetime.now(datetime.timezone.utc),
            approved_at=datetime.datetime.now(datetime.timezone.utc),
        )
        session.add(item)
        await session.commit()
        return {
            "contribution_id": str(item.id),
            "status": "auto_approved",
            "category": category,
            "message": "Knowledge contribution auto-approved and added to the commons.",
        }
    else:
        # Normal flow: insert to pending_contributions queue
        contribution = PendingContribution(
            org_id=auth.org_id,
            source_agent_id=auth.agent_id,
            run_id=run_id,
            content=cleaned_content,
            content_hash=content_hash,
            category=category_enum,
            confidence=confidence,
            framework=framework,
            language=language,
            version=version,
            tags={"tags": tags} if tags else None,
            contributed_at=datetime.datetime.now(datetime.timezone.utc),
        )
        session.add(contribution)
        await session.commit()
        contribution_id = str(contribution.id)

    return {
        "contribution_id": contribution_id,
        "status": "queued",
        "category": category,
        "message": "Knowledge contribution queued for review.",
    }
```

Add `from hivemind.pipeline.embedder import get_embedder` to imports (needed for auto-approve embedding generation).

Remove the existing Step 5 and Step 6 code that was replaced.
  </action>
  <verify>
Run `python -c "from hivemind.server.tools.add_knowledge import add_knowledge; print('add_knowledge importable with injection + auto-approve')"` — should succeed.
Grep the file for "InjectionScanner" and "AutoApproveRule" to confirm both integrations are present.
  </verify>
  <done>add_knowledge scans for prompt injection before PII stripping (SEC-01). If an auto-approve rule matches the org+category, the contribution skips the pending queue and is directly inserted with embedding (TRUST-04). The existing queued flow is preserved as the default path.</done>
</task>

<task type="auto">
  <name>Task 2: Add content hash verification and cross-namespace dedup to search_knowledge</name>
  <files>hivemind/server/tools/search_knowledge.py</files>
  <action>
Modify `hivemind/server/tools/search_knowledge.py` with two enhancements:

**Enhancement 1: Content hash verification in fetch-by-id (SEC-02):**

Add import: `from hivemind.pipeline.integrity import verify_content_hash`

In `_fetch_by_id()`, after retrieving the item and before returning the dict, add hash verification:

```python
# SEC-02: Verify content integrity — detect tampering
if not verify_content_hash(item.content, item.content_hash):
    # Log tamper warning but still return the item with a warning field
    # This is a data integrity issue, not a user error
    import logging
    logging.getLogger(__name__).warning(
        "Content hash mismatch for item %s — possible tampering detected",
        item.id,
    )
    return {
        # ... all existing fields ...
        "integrity_warning": "Content hash mismatch detected — this item may have been tampered with.",
    }
```

Update the normal return dict to include `"integrity_verified": True` so consumers can see the check passed.

**Enhancement 2: Cross-namespace deduplication in search results (ACL-05):**

In `_search()`, after building the `results` list from `rows`, add deduplication by content_hash:

```python
# ACL-05: Deduplicate results by content_hash when spanning private + public
# Private results take priority over public duplicates (org attribution preserved)
seen_hashes: set[str] = set()
deduped_results = []
for item, distance in rows:
    if item.content_hash in seen_hashes:
        continue  # skip duplicate
    seen_hashes.add(item.content_hash)
    deduped_results.append((item, distance))
```

Then build the summary-tier results from `deduped_results` instead of `rows`. The SQL query already sorts by distance ASC and private items (org_id match) naturally come first due to how pgvector returns results, so private items are preferred.

Update the `total_count` to reflect deduplicated count. Since SQL-level dedup is impractical with pgvector (Pitfall from research), adjust the total:
```python
# Adjust total to account for dedup (approximate — exact count would require full scan)
dedup_reduction = len(rows) - len(deduped_results)
total_count = max(0, total_count - dedup_reduction)
```

Note: The existing `(KnowledgeItem.org_id == org_id) | (KnowledgeItem.is_public == True)` WHERE clause already implements cross-namespace search. ACL-05's contribution is the deduplication layer on top.
  </action>
  <verify>
Run `python -c "from hivemind.server.tools.search_knowledge import search_knowledge; print('search_knowledge importable with integrity + dedup')"` — should succeed.
Grep the file for "verify_content_hash" and "seen_hashes" to confirm both integrations are present.
  </verify>
  <done>search_knowledge fetch-by-id verifies content hash on retrieval and includes integrity_verified/integrity_warning in response (SEC-02). Search results are deduplicated by content_hash with private items prioritized over public duplicates (ACL-05).</done>
</task>

</tasks>

<verification>
1. add_knowledge.py imports InjectionScanner and AutoApproveRule
2. add_knowledge flow: validation -> auth -> injection scan -> PII strip -> hash -> auto-approve check -> insert (pending or direct)
3. search_knowledge fetch-by-id calls verify_content_hash() and returns integrity status
4. search_knowledge search mode deduplicates by content_hash before building results
5. Both files import without errors
</verification>

<success_criteria>
- Prompt injection is blocked before PII stripping in add_knowledge (SEC-01 wired)
- Auto-approve rules bypass the pending queue for matching org+category (TRUST-04 wired)
- Content hash is verified on fetch-by-id with integrity status in response (SEC-02 wired)
- Cross-namespace search results are deduplicated by content_hash (ACL-05 wired)
</success_criteria>

<output>
After completion, create `.planning/phases/02-trust-security-hardening/02-05-SUMMARY.md`
</output>
