---
phase: 04-dashboard-distribution
plan: 05
type: execute
wave: 1
depends_on: []
files_modified:
  - wrappers/langchain/pyproject.toml
  - wrappers/langchain/hivemind_langchain/__init__.py
  - wrappers/langchain/hivemind_langchain/retriever.py
  - wrappers/crewai/pyproject.toml
  - wrappers/crewai/hivemind_crewai/__init__.py
  - wrappers/crewai/hivemind_crewai/tool.py
  - skills/SKILL.md
autonomous: true
requirements:
  - DIST-05
  - DIST-07
  - DIST-08

must_haves:
  truths:
    - "A LangChain user can instantiate HiveMindRetriever and use it in any chain expecting a BaseRetriever"
    - "A CrewAI user can add HiveMindTool to an agent's tool list and search the knowledge commons"
    - "An OpenClaw agent can read SKILL.md and call HiveMind REST API to search and contribute knowledge"
  artifacts:
    - path: "wrappers/langchain/hivemind_langchain/retriever.py"
      provides: "LangChain BaseRetriever subclass for HiveMind"
      exports: ["HiveMindRetriever"]
    - path: "wrappers/crewai/hivemind_crewai/tool.py"
      provides: "CrewAI BaseTool subclass for HiveMind"
      exports: ["HiveMindTool"]
    - path: "skills/SKILL.md"
      provides: "OpenClaw AgentSkills spec for HiveMind"
      contains: "hivemind"
  key_links:
    - from: "wrappers/langchain/hivemind_langchain/retriever.py"
      to: "hivemind/api/routes/knowledge.py"
      via: "httpx GET to /api/v1/knowledge/search"
      pattern: "/api/v1/knowledge/search"
    - from: "wrappers/crewai/hivemind_crewai/tool.py"
      to: "hivemind/api/routes/knowledge.py"
      via: "httpx GET to /api/v1/knowledge/search"
      pattern: "/api/v1/knowledge/search"
---

<objective>
Create framework wrappers that let developers integrate HiveMind into their existing AI pipelines: LangChain retriever (PyPI package), CrewAI tool (PyPI package), and OpenClaw skill (SKILL.md file).

Purpose: Developers already using LangChain, CrewAI, or OpenClaw should be able to add HiveMind as a knowledge source without learning MCP. These wrappers are thin HTTP clients calling the existing REST API.
Output: Two Python packages (wrappers/langchain/, wrappers/crewai/) and one SKILL.md file (skills/).
</objective>

<execution_context>
@/Users/amirkellousidhoum/.claude/get-shit-done/workflows/execute-plan.md
@/Users/amirkellousidhoum/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-dashboard-distribution/04-RESEARCH.md
@hivemind/api/routes/knowledge.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: LangChain HiveMindRetriever package</name>
  <files>
    wrappers/langchain/pyproject.toml
    wrappers/langchain/hivemind_langchain/__init__.py
    wrappers/langchain/hivemind_langchain/retriever.py
  </files>
  <action>
Create `wrappers/langchain/` directory structure.

**`wrappers/langchain/pyproject.toml`:**
```toml
[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project]
name = "hivemind-langchain"
version = "0.1.0"
description = "LangChain retriever for HiveMind shared knowledge commons"
readme = "README.md"
license = "MIT"
requires-python = ">=3.10"
dependencies = [
    "langchain-core>=0.2.0",
    "httpx>=0.25.0",
]

[project.urls]
Homepage = "https://github.com/your-org/hivemind"
```

**`wrappers/langchain/hivemind_langchain/__init__.py`:**
```python
from hivemind_langchain.retriever import HiveMindRetriever

__all__ = ["HiveMindRetriever"]
```

**`wrappers/langchain/hivemind_langchain/retriever.py`:**

Subclass `langchain_core.retrievers.BaseRetriever`:

```python
class HiveMindRetriever(BaseRetriever):
    """LangChain retriever that queries the HiveMind knowledge commons."""

    base_url: str  # e.g. "https://your-hivemind.com"
    api_key: str
    limit: int = 10
    category: str | None = None
```

Implement `_get_relevant_documents(query, *, run_manager)`:
1. Use `httpx.get()` (sync) to call `{base_url}/api/v1/knowledge/search` with params `query`, `limit`, `category` (if set).
2. Set `X-API-Key` header.
3. Set timeout of 10 seconds.
4. Call `resp.raise_for_status()`.
5. Parse `resp.json()["results"]`.
6. Return list of `Document(page_content=r["title"] + "\n\n" + r.get("content", ""), metadata={"id": r["id"], "category": r["category"], "confidence": r.get("confidence", 0)})`.
7. Handle empty results: return empty list.

Implement `_aget_relevant_documents(query, *, run_manager)`:
1. Use `httpx.AsyncClient()` as async context manager.
2. Same logic as sync but with `await client.get(...)`.

Anti-pattern from research: do NOT use `httpx.get()` in the async method — use `httpx.AsyncClient()` to avoid blocking the event loop.

Import: `from langchain_core.documents import Document`, `from langchain_core.retrievers import BaseRetriever`, `from langchain_core.callbacks import CallbackManagerForRetrieverRun`.
  </action>
  <verify>
`cd wrappers/langchain && python -c "from hivemind_langchain import HiveMindRetriever; r = HiveMindRetriever(base_url='http://test', api_key='test')"` succeeds without import errors (requires langchain-core installed — verify import path is correct).
  </verify>
  <done>HiveMindRetriever subclasses BaseRetriever with sync and async implementations calling /api/v1/knowledge/search, returning LangChain Documents with metadata.</done>
</task>

<task type="auto">
  <name>Task 2: CrewAI HiveMindTool package</name>
  <files>
    wrappers/crewai/pyproject.toml
    wrappers/crewai/hivemind_crewai/__init__.py
    wrappers/crewai/hivemind_crewai/tool.py
  </files>
  <action>
Create `wrappers/crewai/` directory structure.

**`wrappers/crewai/pyproject.toml`:**
```toml
[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project]
name = "hivemind-crewai"
version = "0.1.0"
description = "CrewAI tool for searching the HiveMind shared knowledge commons"
readme = "README.md"
license = "MIT"
requires-python = ">=3.10"
dependencies = [
    "crewai>=0.100.0",
    "httpx>=0.25.0",
]

[project.urls]
Homepage = "https://github.com/your-org/hivemind"
```

**`wrappers/crewai/hivemind_crewai/__init__.py`:**
```python
from hivemind_crewai.tool import HiveMindTool

__all__ = ["HiveMindTool"]
```

**`wrappers/crewai/hivemind_crewai/tool.py`:**

Subclass `crewai.tools.BaseTool` (import path confirmed in research — Pitfall 4):

Define `HiveMindSearchInput(BaseModel)` with:
- `query: str = Field(..., description="The search query")`
- `category: Optional[str] = Field(None, description="Optional category filter")`
- `limit: int = Field(10, ge=1, le=50, description="Maximum number of results")`

```python
class HiveMindTool(BaseTool):
    name: str = "hivemind_search"
    description: str = (
        "Search the HiveMind shared knowledge commons. "
        "Returns relevant knowledge items contributed by agents across organizations. "
        "Use this to find solutions, workarounds, and domain expertise."
    )
    args_schema: Type[BaseModel] = HiveMindSearchInput
    base_url: str
    api_key: str
```

Implement `_run(query, category=None, limit=10) -> str`:
1. Use `httpx.get()` (sync) to call `{base_url}/api/v1/knowledge/search`.
2. Set `X-API-Key` header, timeout 10s.
3. Parse results.
4. If no results: return `"No relevant knowledge found in the HiveMind commons."`.
5. Format results as a readable string:
   ```
   [category] Title (confidence: X.XX)
   Preview text...

   [category] Title (confidence: X.XX)
   Preview text...
   ```
6. Return the formatted string (CrewAI tools return strings, not structured data).

Note on `_arun`: CrewAI's BaseTool has an optional `_arun` method. Implement it using `httpx.AsyncClient()` with the same logic but async. If CrewAI version doesn't support `_arun`, omit it and add a comment noting it's for future compatibility.
  </action>
  <verify>
`cd wrappers/crewai && python -c "from hivemind_crewai import HiveMindTool; t = HiveMindTool(base_url='http://test', api_key='test')"` succeeds without import errors (requires crewai installed).
  </verify>
  <done>HiveMindTool subclasses BaseTool with Pydantic args_schema, sync _run returning formatted string results, and optional async _arun for future CrewAI versions.</done>
</task>

<task type="auto">
  <name>Task 3: OpenClaw SKILL.md</name>
  <files>skills/SKILL.md</files>
  <action>
Create `skills/` directory at repo root.

**`skills/SKILL.md`:**

Follow the AgentSkills format from research. CRITICAL: frontmatter keys must be single-line only (parser limitation).

```markdown
---
name: hivemind
description: Search and contribute to the HiveMind shared knowledge commons
user-invocable: true
metadata: {"homepage": "https://github.com/your-org/hivemind", "version": "0.1.0"}
---

# HiveMind Knowledge Commons

HiveMind is a shared memory system for AI agents. Use this skill to search the collective knowledge commons — knowledge contributed by agents across organizations including bug fixes, workarounds, configurations, and domain expertise.

## Configuration

Set the following environment variables:
- `HIVEMIND_URL`: Your HiveMind server URL (e.g., https://your-instance.com)
- `HIVEMIND_API_KEY`: Your API key for authentication

## Search Knowledge

To search the knowledge commons, make a GET request:

```
GET {HIVEMIND_URL}/api/v1/knowledge/search?query=<your-query>&limit=10
Header: X-API-Key: {HIVEMIND_API_KEY}
```

The response contains a `results` array with knowledge items, each having:
- `id`: Unique identifier
- `title`: Knowledge title
- `category`: One of bug_fix, workaround, configuration, domain_expertise, tooling, architecture, other
- `confidence`: Relevance confidence score (0-1)

## Report Outcome

After using knowledge, report whether it was helpful:

```
POST {HIVEMIND_URL}/api/v1/outcomes
Header: X-API-Key: {HIVEMIND_API_KEY}
Content-Type: application/json
Body: {"item_id": "<id>", "outcome": "solved" | "did_not_help", "agent_id": "<your-agent-id>"}
```

## MCP Connection (Alternative)

If your runtime supports MCP, connect directly to {HIVEMIND_URL}/mcp for access to all tools:
- add_knowledge, search_knowledge, list_knowledge, delete_knowledge, publish_knowledge, report_outcome
```

Ensure the metadata value in frontmatter is a single-line JSON object (research confirmed parser limitation). Do NOT use multi-line YAML for metadata.
  </action>
  <verify>
`test -f skills/SKILL.md && head -5 skills/SKILL.md` shows the YAML frontmatter starting with `---`. `grep "^metadata:" skills/SKILL.md` confirms single-line JSON metadata value.
  </verify>
  <done>SKILL.md in AgentSkills format with single-line frontmatter, REST API usage instructions for search and outcome reporting, and MCP alternative path.</done>
</task>

</tasks>

<verification>
1. `ls wrappers/langchain/hivemind_langchain/retriever.py wrappers/crewai/hivemind_crewai/tool.py skills/SKILL.md` — all exist
2. Both Python packages have `pyproject.toml` with hatchling build system
3. Both wrappers call `/api/v1/knowledge/search` with X-API-Key header
4. SKILL.md has valid YAML frontmatter with single-line metadata
</verification>

<success_criteria>
- HiveMindRetriever is a proper BaseRetriever subclass with sync and async methods
- HiveMindTool is a proper BaseTool subclass with args_schema and string return
- SKILL.md follows AgentSkills format with REST API instructions
- Both wrapper packages are independently installable (separate pyproject.toml)
- All three wrappers call the existing REST API — no MCP dependency
</success_criteria>

<output>
After completion, create `.planning/phases/04-dashboard-distribution/04-05-SUMMARY.md`
</output>
